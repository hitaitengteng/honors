
@article{urbanowicz_learning_2009,
	title = {Learning {Classifier} {Systems}: {A} {Complete} {Introduction}, {Review}, and {Roadmap}},
	volume = {2009},
	issn = {1687-6229},
	shorttitle = {Learning {Classifier} {Systems}},
	url = {http://dx.doi.org/10.1155/2009/736398},
	doi = {10.1155/2009/736398},
	abstract = {If complexity is your problem, learning classifier systems (LCSs) may offer a solution. These rule-based, multifaceted, machine learning algorithms originated and have evolved in the cradle of evolutionary biology and artificial intelligence. The LCS concept has inspired a multitude of implementations adapted to manage the different problem domains to which it has been applied (e.g., autonomous robotics, classification, knowledge discovery, and modeling). One field that is taking increasing notice of LCS is epidemiology, where there is a growing demand for powerful tools to facilitate etiological discovery. Unfortunately, implementation optimization is nontrivial, and a cohesive encapsulation of implementation alternatives seems to be lacking. This paper aims to provide an accessible foundation for researchers of different backgrounds interested in selecting or developing their own LCS. Included is a simple yet thorough introduction, a historical review, and a roadmap of algorithmic components, emphasizing differences in alternative LCS implementations.},
	urldate = {2016-11-04},
	journal = {J. Artif. Evol. App.},
	author = {Urbanowicz, Ryan J. and Moore, Jason H.},
	month = jan,
	year = {2009},
	pages = {1:1--1:25},
	file = {ACM Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/AJHBZGMH/Urbanowicz and Moore - 2009 - Learning Classifier Systems A Complete Introducti.pdf:application/pdf}
}

@article{fernandez_genetics-based_2010,
	title = {Genetics-{Based} {Machine} {Learning} for {Rule} {Induction}: {State} of the {Art}, {Taxonomy}, and {Comparative} {Study}},
	volume = {14},
	issn = {1089-778X},
	shorttitle = {Genetics-{Based} {Machine} {Learning} for {Rule} {Induction}},
	doi = {10.1109/TEVC.2009.2039140},
	abstract = {The classification problem can be addressed by numerous techniques and algorithms which belong to different paradigms of machine learning. In this paper, we are interested in evolutionary algorithms, the so-called genetics-based machine learning algorithms. In particular, we will focus on evolutionary approaches that evolve a set of rules, i.e., evolutionary rule-based systems, applied to classification tasks, in order to provide a state of the art in this field. This paper has a double aim: to present a taxonomy of the genetics-based machine learning approaches for rule induction, and to develop an empirical analysis both for standard classification and for classification with imbalanced data sets. We also include a comparative study of the genetics-based machine learning (GBML) methods with some classical non-evolutionary algorithms, in order to observe the suitability and high potential of the search performed by evolutionary algorithms and the behavior of the GBML algorithms in contrast to the classical approaches, in terms of classification accuracy.},
	number = {6},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Fernandez, A. and Garcia, S. and Luengo, J. and Bernado-Mansilla, E. and Herrera, F.},
	month = dec,
	year = {2010},
	keywords = {Artificial intelligence, Classification, classification tasks, Classification tree analysis, Computer science, evolutionary algorithms, Evolutionary computation, evolutionary rule-based systems, genetic algorithms, genetics-based machine learning, genetics-based machine learning algorithm, imbalanced data sets, knowledge based systems, Knowledge representation, learning (artificial intelligence), learning classifier systems, Machine learning, Machine learning algorithms, pattern classification, rule induction, Standards development, Taxonomy},
	pages = {913--941},
	file = {IEEE Xplore Abstract Record:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/EUDF3BXU/5491152.html:text/html}
}

@article{nelson_measuring_2016,
	title = {Measuring the {Relative} {Importance} of {Different} {Agricultural} {Inputs} to {Global} and {Regional} {Crop} {Yield} {Growth} {Since} 1975},
	url = {http://digitalcommons.bowdoin.edu/econpapers/12},
	journal = {Economics Department Working Paper Series},
	author = {Nelson, Erik and Congdon, Clare Bates},
	month = sep,
	year = {2016},
	file = {"Measuring the Relative Importance of Different Agricultural Inputs to " by Erik Nelson and Clare Bates Congdon:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/TC88KF3A/12.html:text/html}
}

@incollection{kovacs_genetics-based_2012,
	title = {Genetics-{Based} {Machine} {Learning}},
	copyright = {©2012 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-92909-3 978-3-540-92910-9},
	url = {http://link.springer.com/referenceworkentry/10.1007/978-3-540-92910-9_30},
	abstract = {This is a survey of the field of genetics-based machine learning (GBML): the application of evolutionary algorithms (ES) to machine learning. We assume readers are familiar with evolutionary algorithms and their application to optimization problems, but not necessarily with machine learning. We briefly outline the scope of machine learning, introduce the more specific area of supervised learning, contrast it with optimization and present arguments for and against GBML. Next we introduce a framework for GBML, which includes ways of classifying GBML algorithms and a discussion of the interaction between learning and evolution. We then review the following areas with emphasis on their evolutionary aspects: GBML for subproblems of learning, genetic programming, evolving ensembles, evolving neural networks, learning classifier systems, and genetic fuzzy systems. , Abstract This is a survey of the field of genetics-based machine learning (GBML): the application of evolutionary algorithms (ES) to machine learning. We assume readers are familiar with evolutionary algorithms and their application to optimization problems, but not necessarily with machine learning. We briefly outline the scope of machine learning, introduce the more specific area of supervised learning, contrast it with optimization and present arguments for and against GBML. Next we introduce a framework for GBML, which includes ways of classifying GBML algorithms and a discussion of the interaction between learning and evolution. We then review the following areas with emphasis on their evolutionary aspects: GBML for subproblems of learning, genetic programming, evolving ensembles, evolving neural networks, learning classifier systems, and genetic fuzzy systems.},
	language = {en},
	urldate = {2016-11-04},
	booktitle = {Handbook of {Natural} {Computing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kovacs, Tim},
	editor = {Rozenberg, Grzegorz and Bäck, Thomas and Kok, Joost N.},
	year = {2012},
	note = {DOI: 10.1007/978-3-540-92910-9\_30},
	keywords = {Artificial Intelligence (incl. Robotics), Computational Intelligence, Nanotechnology, Quantum Information Technology, Spintronics, Systems Biology, Theory of Computation},
	pages = {937--986},
	file = {Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/H6CTZ45R/Kovacs - 2012 - Genetics-Based Machine Learning.pdf:application/pdf;Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/VCC2NI3G/10.html:text/html}
}

@article{holmes_learning_2002,
	series = {Evolutionary {Computation}},
	title = {Learning classifier systems: {New} models, successful applications},
	volume = {82},
	issn = {0020-0190},
	shorttitle = {Learning classifier systems},
	url = {http://www.sciencedirect.com/science/article/pii/S0020019001002836},
	doi = {10.1016/S0020-0190(01)00283-6},
	abstract = {Rules are an accepted means of representing knowledge for virtually every domain. Traditional machine learning methods derive rules by exploring sets of examples using statistical or information theoretic techniques. Alternatively, rules can be discovered through methods of Evolutionary Computation such as genetic algorithms and learning classifier systems. In recent years, new models of learning classifier systems have been developed which have resulted in successful applications in a wide variety of domains (e.g., autonomous robotics, classification, knowledge discovery, modeling). These models have led to a resurgence of this area which for a certain period appeared almost at a dead end. This paper overviews the recent developments in learning classifier systems research, the new models, and the most interesting applications, suggesting some of the most relevant future research directions.},
	number = {1},
	urldate = {2016-11-15},
	journal = {Information Processing Letters},
	author = {Holmes, John H. and Lanzi, Pier Luca and Stolzmann, Wolfgang and Wilson, Stewart W.},
	month = apr,
	year = {2002},
	keywords = {Classifier systems, Complexity, Data mining, Generalization, Internal models, Robotics},
	pages = {23--30},
	file = {ScienceDirect Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/FUN85NV6/S0020019001002836.html:text/html}
}

@book{sutton_reinforcement_2016,
	address = {Cambridge, Mass},
	edition = {2nd},
	title = {Reinforcement {Learning}: {An} {Introduction} ({Draft})},
	publisher = {Bradford},
	author = {Sutton, Richard and Barto, Andrew},
	year = {2016}
}

@misc{noauthor_ml_nodate,
	title = {({ML} 1.3) {What} is unsupervised learning? - {YouTube}},
	shorttitle = {({ML} 1.3) {What} is unsupervised learning?},
	url = {https://www.youtube.com/},
	urldate = {2016-11-17},
	file = {Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/XBQX67TA/watch.html:text/html}
}

@incollection{bull_two_2005,
	series = {Studies in {Fuzziness} and {Soft} {Computing}},
	title = {Two {Simple} {Learning} {Classifier} {Systems}},
	isbn = {978-3-540-25073-9 978-3-540-32396-9},
	url = {http://link.springer.com/chapter/10.1007/11319122_4},
	abstract = {Since its introduction Holland’s Learning Classifier System (LCS) [Holland, 1976] has inspired much research into ‘genetics-based’ machine learning [Goldberg, 1989]. Given the complexity of the developed system [Holland, 1986], simplified versions have previously been presented (e.g., [Goldberg, 1989][Wilson, 1994]) to improve both performance and understanding. It has recently been shown that Wilson’s simpler ‘zeroth-level’ system (ZCS) [Wilson, 1994] can perform optimally [Bull \& Hurst, 2002] but “it would appear that the interaction between the rate of rule updates and the fitness sharing process is critical” [ibid.]. In this chapter, a simplified version of ZCS is explored - termed a ‘minimal’ classifier system, MCS.},
	language = {en},
	number = {183},
	urldate = {2016-11-19},
	booktitle = {Foundations of {Learning} {Classifier} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bull, Larry},
	editor = {Bull, Larry and Kovacs, Tim},
	year = {2005},
	note = {DOI: 10.1007/11319122\_4},
	keywords = {Applications of Mathematics, Appl.Mathematics/Computational Methods of Engineering, Artificial Intelligence (incl. Robotics), Bioinformatics},
	pages = {63--89},
	file = {Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/2UESTNRK/Bull - 2005 - Two Simple Learning Classifier Systems.pdf:application/pdf;Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/WGERAZ7K/11319122_4.html:text/html}
}

@book{freitas_data_2002,
	address = {Berlin ; New York},
	edition = {2002 edition},
	title = {Data {Mining} and {Knowledge} {Discovery} with {Evolutionary} {Algorithms}},
	isbn = {978-3-540-43331-6},
	abstract = {This book integrates two areas of computer science, namely data mining and evolutionary algorithms. Both these areas have become increasingly popular in the last few years, and their integration is currently an active research area. In general, data mining consists of extracting knowledge from data. The motivation for applying evolutionary algorithms to data mining is that evolutionary algorithms are robust search methods which perform a global search in the space of candidate solutions. This book emphasizes the importance of discovering comprehensible, interesting knowledge, which is potentially useful for intelligent decision making. The text explains both basic concepts and advanced topics},
	language = {English},
	publisher = {Springer},
	author = {Freitas, Alex A.},
	month = oct,
	year = {2002}
}

@article{quinlan_induction_1986,
	title = {Induction of {Decision} {Trees}},
	volume = {1},
	issn = {0885-6125},
	url = {http://dx.doi.org/10.1023/A:1022643204877},
	doi = {10.1023/A:1022643204877},
	abstract = {The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.},
	number = {1},
	urldate = {2016-11-23},
	journal = {Mach. Learn.},
	author = {Quinlan, J. R.},
	month = mar,
	year = {1986},
	keywords = {Classification, decision trees, expert systems, induction, information theory, knowledge acquisition},
	pages = {81--106}
}

@article{lawrence_genetics-based_nodate,
	title = {Genetics-{Based} {Machine} {Learning}: {Background} and {Introductory} {Survey} of {Major} {Paradigms}},
	shorttitle = {Genetics-{Based} {Machine} {Learning}},
	url = {http://www.academia.edu/7532421/Genetics-Based_Machine_Learning_Background_and_Introductory_Survey_of_Major_Paradigms},
	abstract = {Genetics-Based Machine Learning: Background and Introductory Survey of Major Paradigms},
	urldate = {2016-11-24},
	author = {Lawrence, Daniel},
	file = {Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/6SMHACT4/Genetics-Based_Machine_Learning_Background_and_Introductory_Survey_of_Major_Paradigms.html:text/html}
}

@book{holland_adaptation_1975,
	address = {Oxford, England},
	title = {Adaptation in natural and artificial systems: {An} introductory analysis with applications to biology, control, and artificial intelligence},
	volume = {viii},
	copyright = {(c) 2016 APA, all rights reserved},
	isbn = {978-0-472-08460-9},
	shorttitle = {Adaptation in natural and artificial systems},
	abstract = {Analyzes and exploits nonadditive system interactions by generalizing the biological concept of "a coadapted set of alleles," and applies a constructive mathematical theory to the full range of adaptive processes, providing both hypotheses for natural systems and algorithms for artificial systems.},
	publisher = {U Michigan Press},
	author = {Holland, John H.},
	year = {1975},
	keywords = {*Adaptation, Mathematical Modeling},
	file = {APA PsycNET Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/75PIAN9T/index.html:text/html}
}

@article{hyafil_constructing_1976,
	title = {Constructing {Optimal} {Binary} {Decision} {Trees} is {NP}-{Complete}},
	volume = {5},
	url = {https://people.csail.mit.edu/rivest/HyafilRivest-ConstructingOptimalBinaryDecisionTreesIsNPComplete.pdf},
	number = {1},
	journal = {Information Processing Letters},
	author = {Hyafil, Laurent and Rivest, Ronald L.},
	month = may,
	year = {1976},
	pages = {15--17}
}

@incollection{keijzer_evolving_2001,
	title = {Evolving {Objects}: {A} {General} {Purpose} {Evolutionary} {Computation} {Library}},
	shorttitle = {Evolving {Objects}},
	url = {http://link.springer.com/chapter/10.1007/3-540-46033-0_19},
	abstract = {This paper presents the evolving objects library (EOlib), an object-oriented framework for evolutionary computation (EC) that aims to provide a fiexible set of classes to build EC applications. EOlib design objective is to be able to evolve any object in which fitness makes sense. In order to do so, EO concentrates on interfaces; any object can evolve if it is endowed with an interface to do so. In this paper, we describe what features an object must have in order to evolve, and some examples of how EO has been put to practice evolving neural networks, solutions to the Mastermind game, and other novel applications.},
	language = {en},
	urldate = {2016-11-30},
	booktitle = {Artificial {Evolution}},
	publisher = {Springer Berlin Heidelberg},
	author = {Keijzer, M. and Merelo, J. J. and Romero, G. and Schoenauer, Marc},
	month = oct,
	year = {2001},
	note = {DOI: 10.1007/3-540-46033-0\_19},
	pages = {231--242},
	file = {Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/AMDN3MQK/Keijzer et al. - 2001 - Evolving Objects A General Purpose Evolutionary C.pdf:application/pdf;Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/FRUACBPZ/3-540-46033-0_19.html:text/html}
}

@article{bernado-mansilla_accuracy-based_2003,
	title = {Accuracy-based learning classifier systems: models, analysis and applications to classification tasks},
	volume = {11},
	issn = {1063-6560},
	shorttitle = {Accuracy-based learning classifier systems},
	doi = {10.1162/106365603322365289},
	abstract = {Recently, Learning Classifier Systems (LCS) and particularly XCS have arisen as promising methods for classification tasks and data mining. This paper investigates two models of accuracy-based learning classifier systems on different types of classification problems. Departing from XCS, we analyze the evolution of a complete action map as a knowledge representation. We propose an alternative, UCS, which evolves a best action map more efficiently. We also investigate how the fitness pressure guides the search towards accurate classifiers. While XCS bases fitness on a reinforcement learning scheme, UCS defines fitness from a supervised learning scheme. We find significant differences in how the fitness pressure leads towards accuracy, and suggest the use of a supervised approach specially for multi-class problems and problems with unbalanced classes. We also investigate the complexity factors which arise in each type of accuracy-based LCS. We provide a model on the learning complexity of LCS which is based on the representative examples given to the system. The results and observations are also extended to a set of real world classification problems, where accuracy-based LCS are shown to perform competitively with respect to other learning algorithms. The work presents an extended analysis of accuracy-based LCS, gives insight into the understanding of the LCS dynamics, and suggests open issues for further improvement of LCS on classification tasks.},
	language = {eng},
	number = {3},
	journal = {Evolutionary Computation},
	author = {Bernadó-Mansilla, Ester and Garrell-Guiu, Josep M.},
	year = {2003},
	pmid = {14558911},
	keywords = {Algorithms, Artificial intelligence, Classification, Computational Biology, decision trees, Humans, Learning, Models, Genetic, Models, Statistical},
	pages = {209--238}
}

@article{orriols-puig_fuzzy-ucs:_2009,
	title = {Fuzzy-{UCS}: {A} {Michigan}-{Style} {Learning} {Fuzzy}-{Classifier} {System} for {Supervised} {Learning}},
	volume = {13},
	issn = {1089-778X},
	shorttitle = {Fuzzy-{UCS}},
	doi = {10.1109/TEVC.2008.925144},
	abstract = {This paper presents Fuzzy-UCS, a Michigan-style learning fuzzy-classifier system specifically designed for supervised learning tasks. Fuzzy-UCS is inspired by UCS, an on-line accuracy-based learning classifier system. Fuzzy-UCS introduces a linguistic representation of the rules with the aim of evolving more readable rule sets, while maintaining similar performance and generalization capabilities to those presented by UCS. The behavior of Fuzzy-UCS is analyzed in detail from several perspectives. The granularity of the linguistic fuzzy representation to define complex decision boundaries is illustrated graphically, and the test performance obtained with different inference schemes is studied. Fuzzy-UCS is also compared with a large set of other fuzzy and nonfuzzy learners, demonstrating the competitiveness of its on-line architecture in terms of performance and interpretability. Finally, the paper shows the advantages obtained when Fuzzy-UCS is applied to learn fuzzy models from large volumes of data.},
	number = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Orriols-Puig, A. and Casillas, J. and Bernado-Mansilla, E.},
	month = apr,
	year = {2009},
	keywords = {fuzzy set theory, Fuzzy-UCS, Genetic fuzzy systems, inference mechanisms, inference schemes, learning (artificial intelligence), linguistic fuzzy representation, Michigan-style learning classifier systems, Michigan-style learning fuzzy-classifier system, pattern classification, supervised learning},
	pages = {260--283},
	file = {IEEE Xplore Abstract Record:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/H3FVQVFK/4589217.html:text/html}
}

@book{lanzi_learning_2000,
	address = {New York, NY, USA},
	series = {Lecture {Notes} in {Artificial} {Intelligence}},
	title = {Learning {Classifier} {Systems}: {From} {Foundations} to {Applications}},
	volume = {1813},
	publisher = {Springer},
	editor = {Lanzi, Pier Luca and Stolzmann, Wolfgang and Wilson, Stewart W.},
	year = {2000}
}

@inproceedings{lanzi_study_1997,
	title = {A {Study} of the {Generalization} {Capabilities} of {XCS}},
	abstract = {We analyze the generalization behavior of the XCS classifier system in environments in which only a few generalizations can be done. Experimental results presented in the paper evidence that the generalization mechanism of XCS can prevent it from learning even simple tasks in such environments. We present a new operator, named Specify, which contributes to the solution of this problem. XCS with the Specify operator, named XCSS, is compared to XCS in terms of performance and generalization capabilities in different types of environments. Experimental results show that XCSS can deal with a greater variety of environments and that it is more robust than XCS with respect to population size. 1 INTRODUCTION  XCS is a classifier system recently proposed by Wilson (Wilson 1995) which has a strong tendency to evolve near-minimal populations of accurate and maximally general classifiers. Experimental results reported in the literature show that XCS can learn a more compact representation than th...},
	booktitle = {In {Proceedings} of the {Seventh} {International} {Conference} on {Genetic} {Algorithms}},
	publisher = {Morgan Kaufmann},
	author = {Lanzi, Pier Luca},
	year = {1997},
	pages = {418--425},
	file = {Citeseer - Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/XU6368M3/Lanzi - 1997 - A Study of the Generalization Capabilities of XCS.pdf:application/pdf;Citeseer - Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/9MUKFCHI/summary.html:text/html}
}

@book{wilson_generalization_1996,
	title = {Generalization in {XCS}},
	abstract = {This paper studies two changes to XCS, a classifier system in which fitness is based on prediction accuracy and the genetic algorithm takes place in environmental niches. The changes were aimed at increasing XCS's existing tendency to evolve accurate, maximally general classifiers. One change moves the site of the GA from the match set to the action set. The other replaces certain offspring by clones of their parents. The changes are tested on previously employed "woods" and multiplexer tasks. Together they bring XCS close to evolving populations whose high-fitness classifiers form a near-minimal, accurate, maximally general cover of the input and action product space. The results also suggest that, on the multiplexer task, the learning complexity for XCS is polynomial in the number of generalizations.  1 Introduction  XCS (Wilson 1995) is a recently developed classifier system that differs from traditional classifier systems primarily in its definition of classifier fitness. The new f...},
	author = {Wilson, S. W. and Xcs, Generalization},
	year = {1996},
	file = {Citeseer - Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/6ZWAKAZ4/Wilson and Xcs - 1996 - Generalization in XCS.pdf:application/pdf;Citeseer - Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/46IIDZMH/summary.html:text/html}
}

@article{butz_algorithmic_2002,
	title = {An algorithmic description of {XCS}},
	volume = {6},
	issn = {1432-7643},
	url = {http://link.springer.com/article/10.1007/s005000100111},
	doi = {10.1007/s005000100111},
	abstract = {A concise description of the XCS classifier system's parameters, structures, and algorithms is presented as an aid to research. The algorithms are written in modularly structured pseudo code with accompanying explanations.},
	language = {en},
	number = {3-4},
	urldate = {2017-01-12},
	journal = {Soft Computing},
	author = {Butz, M. V. and Wilson, S. W.},
	month = jun,
	year = {2002},
	pages = {144--153},
	file = {Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/N5C7UN33/s005000100111.html:text/html}
}

@inproceedings{j_reducing_1987,
	address = {Hillsdale, New Jersey},
	title = {Reducing {Bias} and {Inefficiency} in the {Selection} {Algorithm}},
	url = {http://en.journals.sid.ir/ViewPaper.aspx?ID=332444},
	language = {En},
	urldate = {2017-04-04},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Genetic} {Algorithms} and their {Application}},
	publisher = {L. Eerlbaum Associates},
	author = {J, Baker},
	year = {1987},
	pages = {14--21},
	file = {Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/N36I2DWK/ViewPaper.html:text/html}
}

@article{wilson_classifier_1995,
	title = {Classifier {Fitness} {Based} on {Accuracy}},
	volume = {3},
	issn = {1063-6560},
	url = {http://dx.doi.org/10.1162/evco.1995.3.2.149},
	doi = {10.1162/evco.1995.3.2.149},
	abstract = {In many classifier systems, the classifier strength parameter serves as a predictor of future payoff and as the classifier's fitness for the genetic algorithm. We investigate a classifier system, XCS, in which each classifier maintains a prediction of expected payoff, but the classifier's fitness is given by a measure of the prediction's accuracy. The system executes the genetic algorithm in niches defined by the match sets, instead of panmictically. These aspects of XCS result in its population tending to form a complete and accurate mapping X × A → P from inputs and actions to payoff predictions. Further, XCS tends to evolve classifiers that are maximally general, subject to an accuracy criterion. Besides introducing a new direction for classifier system research, these properties of XCS make it suitable for a wide range of reinforcement learning situations where generalization over states is desirable.},
	number = {2},
	urldate = {2017-04-05},
	journal = {Evolutionary Computation},
	author = {Wilson, Stewart W.},
	month = jun,
	year = {1995},
	pages = {149--175},
	file = {Evolutionary Computation Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/KXD7RA43/evco.1995.3.2.html:text/html}
}

@inproceedings{holland_properties_1985,
	address = {Hillsdale, NJ, USA},
	title = {Properties of the {Bucket} {Brigade}},
	isbn = {978-0-8058-0426-3},
	url = {http://dl.acm.org/citation.cfm?id=645511.657087},
	urldate = {2017-04-05},
	booktitle = {Proceedings of the 1st {International} {Conference} on {Genetic} {Algorithms}},
	publisher = {L. Erlbaum Associates Inc.},
	author = {Holland, John H.},
	year = {1985},
	pages = {1--7}
}

@inproceedings{wilson_critical_1989,
	address = {San Francisco, CA, USA},
	title = {A {Critical} {Review} of {Classifier} {Systems}},
	url = {http://dl.acm.org/citation.cfm?id=93126.93211},
	urldate = {2017-04-06},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {Genetic} {Algorithms}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Wilson, Stewart W. and Goldberg, David E.},
	year = {1989},
	pages = {244--255}
}

@incollection{lanzi_roadmap_2000,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Roadmap} to the {Last} {Decade} of {Learning} {Classifier} {System} {Research} ({From} 1989 to 1999)},
	copyright = {©2000 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-67729-1 978-3-540-45027-6},
	url = {http://link.springer.com/chapter/10.1007/3-540-45027-0_2},
	abstract = {In 1989 Wilson and Goldberg presented a critical review of the first ten years of learning classifier system research. With this paper we review the subsequent ten years of learning classifier systems research, discussing the main achievements and the major research directions pursued in those years.},
	language = {en},
	number = {1813},
	urldate = {2017-04-06},
	booktitle = {Learning {Classifier} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lanzi, Pier Luca and Riolo, Rick L.},
	editor = {Lanzi, Pier Luca and Stolzmann, Wolfgang and Wilson, Stewart W.},
	year = {2000},
	note = {DOI: 10.1007/3-540-45027-0\_2},
	keywords = {Artificial Intelligence (incl. Robotics), Computation by Abstract Devices, Mathematical Logic and Formal Languages},
	pages = {33--61},
	file = {Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/85PVR3PF/Lanzi and Riolo - 2000 - A Roadmap to the Last Decade of Learning Classifie.pdf:application/pdf;Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/Z6XW6JJ3/3-540-45027-0_2.html:text/html}
}

@incollection{wilson_state_2000,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {State of {XCS} {Classifier} {System} {Research}},
	copyright = {©2000 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-67729-1 978-3-540-45027-6},
	url = {http://link.springer.com/chapter/10.1007/3-540-45027-0_3},
	abstract = {XCS is a new kind of learning classifier system that differs from the traditional kind primarily in its definition of classifier fitness and its relation to contemporary reinforcement learning. Advantages of XCS include improved performance and an ability to form accurate maximal generalizations. This paper reviews recent research on XCS with respect to representation, internal state, predictive modeling, noise, and underlying theory and technique. A notation for environmental regularities is introduced.},
	language = {en},
	number = {1813},
	urldate = {2017-04-06},
	booktitle = {Learning {Classifier} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Wilson, Stewart W.},
	editor = {Lanzi, Pier Luca and Stolzmann, Wolfgang and Wilson, Stewart W.},
	year = {2000},
	note = {DOI: 10.1007/3-540-45027-0\_3},
	keywords = {Artificial Intelligence (incl. Robotics), Computation by Abstract Devices, Mathematical Logic and Formal Languages},
	pages = {63--81},
	file = {Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/98EKG2PW/Wilson - 2000 - State of XCS Classifier System Research.pdf:application/pdf;Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/JPRSGBXS/3-540-45027-0_3.html:text/html}
}

@phdthesis{c._j._c._h._learning_1989,
	title = {Learning from {Delayed} {Rewards}},
	author = {C. J. C. H., Watkins},
	year = {1989}
}

@inproceedings{schaffer_multi-objective_1985,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'85},
	title = {Multi-objective {Learning} via {Genetic} {Algorithms}},
	isbn = {978-0-934613-02-6},
	url = {http://dl.acm.org/citation.cfm?id=1625135.1625248},
	abstract = {Genetic algorithms (GAs) are powerful, general purpose adaptive search techniques which have been used successfully in a variety of learning systems. In the standard formulation, GAs maintain a set of alternative knowledge structures for the task to be learned, and improved knowledge structures are formed through a combination of competition and knowledge sharing among the alternative knowledge structures. In this paper, we extend the GA paradigm by allowing multidimensional feedback concerning the performance of the alternative structures. The modified GA is shown to solve a multiclass pattern discrimination task which could not be solved by the unmodified GA.},
	urldate = {2017-04-07},
	booktitle = {Proceedings of the 9th {International} {Joint} {Conference} on {Artificial} {Intelligence} - {Volume} 1},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Schaffer, J. David and Grefenstette, John J.},
	year = {1985},
	pages = {593--595}
}

@inproceedings{manuel_valenzuela-rendon_fuzzy_1991,
	address = {San Diego, CA},
	title = {The {Fuzzy} {Classifier} {System}: {A} {Classifier} {System} for {Continuously} {Varying} {Variables}"},
	author = {{Manuel Valenzuela-Rendón}},
	year = {1991}
}

@article{holland_cognitive_1977,
	title = {Cognitive {Systems} {Based} on {Adaptive} {Algorithms}},
	issn = {0163-5719},
	url = {http://doi.acm.org/10.1145/1045343.1045373},
	doi = {10.1145/1045343.1045373},
	abstract = {The type of cognitive system (CS) studied here has four basic parts: (1) a set of interacting elementary productions, called classifiers, (2) a performance algorithm that directs the action of the system in the environment, (3) a simple learning algorithm that keeps a record of each classifier's success in bringing about rewards, and (4) a more complex learning algorithm, called the genetic algorithm, that modifies the set of classifiers so that variants of good classifiers persist and new, potentially better ones are created in a provably efficient manner.},
	number = {63},
	urldate = {2017-04-08},
	journal = {SIGART Bull.},
	author = {Holland, John H. and Reitman, Judith S.},
	month = jun,
	year = {1977},
	pages = {49--49},
	file = {ACM Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/KHZVC4XZ/Holland and Reitman - 1977 - Cognitive Systems Based on Adaptive Algorithms.pdf:application/pdf}
}

@misc{us_epa_climate_2017,
	type = {Overviews and {Factsheets}},
	title = {Climate {Impacts} on {Agriculture} and {Food} {Supply}},
	url = {https://www.epa.gov/climate-impacts/climate-impacts-agriculture-and-food-supply},
	abstract = {This page discusses the projected climate change impacts on U.S. Agriculture and Food Supply},
	language = {en},
	urldate = {2017-04-09},
	author = {US EPA, OA},
	year = {2017},
	file = {Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/CQ39BKD8/climate-impacts-agriculture-and-food-supply.html:text/html}
}

@misc{noauthor_world_2015,
	title = {World population projected to reach 9.7 billion by 2050 {\textbar} {UN} {DESA} {\textbar} {United} {Nations} {Department} of {Economic} and {Social} {Affairs}},
	url = {2015-report.html},
	urldate = {2017-04-09},
	month = jul,
	year = {2015},
	file = {Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/USXPBVZH/2015-report.html:text/html}
}

@incollection{bacardit_data_2007,
	title = {Data {Mining} in {Learning} {Classifier} {Systems}: {Comparing} {XCS} with {GAssist}},
	shorttitle = {Data {Mining} in {Learning} {Classifier} {Systems}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-71231-2_19},
	abstract = {This paper compares performance of the Pittsburgh-style system GAssist with the Michigan-style system XCS on several datamining problems. Our analysis shows that both systems are suitable for datamining but have different advantages and disadvantages. The study does not only reveal important differences between the two systems but also suggests several structural properties of the underlying datasets.},
	language = {en},
	urldate = {2017-04-09},
	booktitle = {Learning {Classifier} {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Bacardit, Jaume and Butz, Martin V.},
	year = {2007},
	note = {DOI: 10.1007/978-3-540-71231-2\_19},
	pages = {282--290},
	file = {Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/V4MJWXIJ/Bacardit and Butz - 2007 - Data Mining in Learning Classifier Systems Compar.pdf:application/pdf;Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/C43XE43D/978-3-540-71231-2_19.html:text/html}
}

@inproceedings{llora_towards_2007,
	address = {New York, NY, USA},
	series = {{GECCO} '07},
	title = {Towards {Better} {Than} {Human} {Capability} in {Diagnosing} {Prostate} {Cancer} {Using} {Infrared} {Spectroscopic} {Imaging}},
	isbn = {978-1-59593-697-4},
	url = {http://doi.acm.org/10.1145/1276958.1277366},
	doi = {10.1145/1276958.1277366},
	abstract = {Cancer diagnosis is essentially a human task. Almost universally, the process requires the extraction of tissue (biopsy) and examination of its microstructure by a human. To improve diagnoses based on limited and inconsistent morphologic knowledge, a new approach has recently been proposed that uses molecular spectroscopic imaging to utilize microscopic chemical composition for diagnoses. In contrast to visible imaging, the approach results in very large data sets as each pixel contains the entire molecular vibrational spectroscopy data from all chemical species. Here, we propose data handling and analysis strategies to allow computer-based diagnosis of human prostate cancer by applying a novel genetics-based machine learning technique (\{\vphantom{\}}{\textbackslash}tt NAX). We apply this technique to demonstrate both fast learning and accurate classification that, additionally, scales well with parallelization. Preliminary results demonstrate that this approach can improve current clinical practice in diagnosing prostate cancer.},
	urldate = {2017-04-09},
	booktitle = {Proceedings of the 9th {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {ACM},
	author = {Llorà, Xavier and Reddy, Rohith and Matesic, Brian and Bhargava, Rohit},
	year = {2007},
	keywords = {genetics-based machine learning, learning classifier system, parallelization, prostate cancer},
	pages = {2098--2105},
	file = {ACM Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/HWSDMM66/Llorà et al. - 2007 - Towards Better Than Human Capability in Diagnosing.pdf:application/pdf}
}

@inproceedings{gao_learning_2005,
	address = {New York, NY, USA},
	series = {{GECCO} '05},
	title = {Learning {Classifier} {System} {Ensemble} for {Data} {Mining}},
	url = {http://doi.acm.org/10.1145/1102256.1102268},
	doi = {10.1145/1102256.1102268},
	abstract = {This paper proposes LCSE, a learning classifier system ensemble, which is an extension of the classical learning classifier system(LCS). The classical LCS includes two major modules, a genetic algorithm module used to facilitate rule discovery, and a reinforcement learning module used to adjust the strength of the corresponding rules while it receives the rewards from the environment. In LCSE we build a two-level ensemble architecture to enhance the generalization of LCS. In the first-level, new instances are first bootstrapped and sent to several LCSs for classification. Then, in the second-level, a plurality-vote method is used to combine the classification results of individual LCSs into a final decision. Experiments on some benchmark data sets from the UCI repository have shown that LCSE has better generalization ability than the single LCS and other supervised learning methods.},
	urldate = {2017-04-10},
	booktitle = {Proceedings of the 7th {Annual} {Workshop} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {ACM},
	author = {Gao, Yang and Huang, Joshua Zhexue and Rong, Hongqiang and Gu, Daqian},
	year = {2005},
	keywords = {ensemble, learning classifier system},
	pages = {63--66},
	file = {ACM Full Text PDF:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/XQE7MQFN/Gao et al. - 2005 - Learning Classifier System Ensemble for Data Minin.pdf:application/pdf}
}

@techreport{hai_h._dam_bcs:_2006,
	address = {Cardiff, UK},
	title = {{BCS}: {Bayesian} {Learning} {Classifier} {System}},
	number = {TR-ALAR-200604005},
	institution = {The Artificla and Adaptive Robotics Laboratory, School of Information Technology and Electrical Engineering, University of New South Wales},
	author = {{Hai H. Dam} and {Hussien A. Abbass} and {Chris Lokan}},
	year = {2006}
}

@techreport{tobias_blickle_comparison_1995,
	address = {Zurich},
	title = {A {Comparison} of {Selection} {Schemes} used in {Genetic} {Algorithms}},
	number = {11},
	institution = {Computer Engineering and Communication Networks Lab, Swiss Federal Institute of Technology (ETH)},
	author = {{Tobias Blickle} and {Lothar Thiele}},
	month = dec,
	year = {1995}
}

@misc{noauthor_file:computational.science.genetic.algorithm.crossover.one.point.svg_nodate,
	title = {File:{Computational}.science.{Genetic}.algorithm.{Crossover}.{One}.{Point}.svg - {Wikimedia} {Commons}},
	url = {https://commons.wikimedia.org/wiki/File:Computational.science.Genetic.algorithm.Crossover.One.Point.svg#file},
	urldate = {2017-04-12},
	journal = {Wikimedia Commons},
	file = {File\:Computational.science.Genetic.algorithm.Crossover.One.Point.svg - Wikimedia Commons:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/DABJG65N/FileComputational.science.Genetic.algorithm.Crossover.One.Point.html:text/html}
}

@misc{assumed_diagram_2007,
	title = {A diagram illustrating the {Stochastic} {Universal} {Sampling} operation. {In} this illustration 4 individuals are being selected ({N}=4), resulting in the selection of {A}, {B}, {C} and {F}.},
	url = {https://commons.wikimedia.org/wiki/File:Statistically_Uniform.png},
	urldate = {2017-04-12},
	author = {Simon Hatthon},
	month = jan,
	year = {2007},
	file = {Wikimedia Snapshot:/Users/willgantt/Library/Application Support/Firefox/Profiles/s7sw5sxj.default-1442312185744/zotero/storage/EE3FXK26/FileStatistically_Uniform.html:text/html}
}
